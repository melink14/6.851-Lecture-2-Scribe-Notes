\documentclass[11pt]{article}
\usepackage{latexsym}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{epsfig}
\usepackage{psfig}

\newcommand{\handout}[5]{
  \noindent
  \begin{center}
  \framebox{
    \vbox{
      \hbox to 5.78in { {\bf 6.851: Advanced Data Structures } \hfill #2 }
      \vspace{4mm}
      \hbox to 5.78in { {\Large \hfill #5  \hfill} }
      \vspace{2mm}
      \hbox to 5.78in { {\em #3 \hfill #4} }
    }
  }
  \end{center}
  \vspace*{4mm}
}

\newcommand{\lecture}[4]{\handout{#1}{#2}{#3}{Scribe: #4}{Lecture #1}}

\newtheorem{theorem}{Theorem}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{observation}[theorem]{Observation}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{fact}[theorem]{Fact}
\newtheorem{assumption}[theorem]{Assumption}

% 1-inch margins, from fullpage.sty by H.Partl, Version 2, Dec. 15, 1988.
\topmargin 0pt
\advance \topmargin by -\headheight
\advance \topmargin by -\headsep
\textheight 8.9in
\oddsidemargin 0pt
\evensidemargin \oddsidemargin
\marginparwidth 0.5in
\textwidth 6.5in

\parindent 0in
\parskip 1.5ex
%\renewcommand{\baselinestretch}{1.25}

\begin{document}

\lecture{2 --- 02/09, 2012}{Spring 2012}{Prof.\ Erik Demaine}{Erek Speed, Victor Jakubiuk}

\section{Overview}

The main idea of the persistent data structures is that when you make a change in the past, you get an entirely new universe. A more science-fiction approach to time travel is that you can make changes in the past and see its result not only in the current state of the data structure, but also all the changes in between the past and now.

We maintain one timeline of updates and queries for a persistent data structure:

[img of a timeline]

blah blah blah

Normally, we always append the operations at the end of the timeline (present time). With retroactive data structures we can do that in the past too.

\section{Retroactivity}

The following operations are supported by retroactive DS:

\begin{itemize}
\item {\em Insert(t, update)} - inserts operation ``update'' at time $t$
\item {\em Delete(t)} - deletes the operation at time $t$
\item {\em Query(t, query)} queries the DS with a ``query'' at time $t$
\end{itemize}

Uppercase Insert indicates an operation on retroactive DS, lowercase is the operation on the actual DS.

You can think of time $t$ as integers, but a better approach is to use an order-maintanance DS to avoid using non-integers (in case you want to insert an operation between times $t$ and $t+1$), as mentioned in the first lecture.

There are three types of retroactivity:
\begin{itemize}
\item {\em Partial} - Query always done at $t = \infty$ (now)
\item {\em Full} - Query at any time $t$ (possibly in the past)
\item {\em Nonoblivious} - Insert, Delete, Query at any time $t$, also if an operation modifies DS, we must say which future queries are changed.
\end{itemize}

\subsection{Easy case with commutativity and inversions}

Assume the following hold:
\begin{itemize}
\item {\em Commutative updates:} $x.y = y.x$ ($x$ followed by $y$ is the same as $y$ followed by $x$), that is the updates can be reordered $\Rightarrow$ Insert(t, op) = Insert(now, op).
\item {\em Invertible updates:} There exist operations $x^{-1}$, such that $x.x^{-1} = \empty \Rightarrow$ Delete(t, op) = Insert(now, op$^{-1}$)
\end{itemize}

\subsubsection{Partial retroactivity}

These two assumptions allow us to solve some problems easily:
\begin{itemize}
\item {\em hashing} 
\item {\em array} with operation $A[i] += \Delta$ (but no direct assignment)
\end{itemize}

\subsection{Full retroactivity}

First, lets define the {\bf search problem}: maintain set $S$ of objects, subject to insert, delete, query($x, S$).

{\bf Decomposable search problem} [1980, 2007]: same as the search problem, with a restriction that the query must satisfy:
query($x, A \Cup B) = f($query$(x, A), $query($x, B))$, for some function $f$ computed in $O(1)$ (sets $A and B$ may overlap). Examples of problems with such a function include:

\begin{itemize}
\item {\em Dynamic nearest neighbor}
\item {\em Successor on a line}
\item {\em Point location}
\end{itemize}

Claim: Full Retroactivity for decomposable search problems (with commutativity and inversions) in $O(\lg{m})$ factor overhead both in time and space (where $m$ is the number of operations): via {\bf segment tree} [1980, Bentley & Saxon (??)]

What is a segment tree?

[img of a st, ~16min of the video]

We want to build a balanced search tree on time, leaves are time. Every element ``lives'' in the data structure on the interval of time, corresponding to its insertion and deletion. Each element appears in $\log{n}$ nodes.

To query on this tree at time $t$, we want to know what operations have been done on this tree from the beginning of time to $t$. Because the query is decomposable, we can look at $\log{n}$ different nodes and combine the results (using function $f$). 

Update: Partition interval of time
Query(t): walk up from leaf

\subsection{General case of full retroactivity}

{\bf Roll back method}: write down the chain of operations and queries; change $r$ time units in the past with factor $O(r)$ overhead. 

That's the best we can do in general. 

Lower bound: $\Omega (r)$ overhead necessary.
Proof: Data Structure maintains 2 values (registers): $X$ and $Y$, initially $\empty$. The following operations are supported: $X = x$, $y += \Delta$, $y = x.y$, query '$y?$'. Perform the following operations (Cramer's rule):
$Y += a_n$,
$X = X.Y$, 
$Y += a_{n-1}$, 
$X = X.y$, 
\ldots
$Y += a_0$,


which is equivalent to computing $Y = a_n X^{n} + a_{n-1} X^{n-1} + ... + a_0$. 
Now, execute Insert($t = 0, X=x$), which changes where the polynomial is evaluated. This cannot be done faster than re-evaluating the polynomial. In history-independent algebraict decision tree, for any field, independent of pre-processing of the coefficients, need $\Omega(n)$ field operations (result from 2001), where $n$ is the degree of the polynomial.







\subsection{Blah blah blah}
Here is a subsection.

\subsubsection{Blah blah blah}
Here is a subsubsection. You can use these as well.

\subsection{Using Boldface}
Make sure to use lots of boldface.

\paragraph{Question:}
How would you use boldface?

\paragraph{Example:}
This is an example showing how to use boldface to 
help organize your lectures.


\paragraph{Some Formatting.}
Here is some formatting that you can use in your notes:
\begin{itemize}
\item {\em Item One} -- This is the first item.
\item {\em Item Two} -- This is the second item.
\item \dots and here are other items.
\end{itemize}

If you need to number things, you can use this style:
\begin{enumerate}
\item {\em Item One} -- Again, this is the first item.
\item {\em Item Two} -- Again, this is the second item.
\item \dots and here are other items.
\end{enumerate}

\paragraph{Bibliography.}
Please give real bibliographical citations for the papers that we
mention in class. See below for how to include a bibliography section.
If you use BibTeX, integrate the .bbl file into your .tex
source. You should reference papers like this: ``The FKS
dictionary originates in a paper by Fredman, Koml\'{o}s and
Szemer\'{e}di \cite{fks}.'' In general, the name of the authors should
appear in text at most once (for the first citation); further
citations look like: ``Our proof follows that of \cite{fks}''.

Take a look at previous lectures (TeX files are available) to see the
details. A excellent source for bibliographical citations is
DBLP. Just Google DBLP and an author's name.


%\bibliography{mybib}
\bibliographystyle{alpha}

\begin{thebibliography}{77}

\bibitem{fks}
M. Fredman, J. Koml\'{o}s, E. Szemer\'{e}di,
\emph{Storing a Sparse Table with $O(1)$ Worst Case Access Time},
Journal of the ACM, 31(3):538-544, 1984.

\end{thebibliography}

\end{document}
